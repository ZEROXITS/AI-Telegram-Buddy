[Bot]
token = 

[Ai]
prompt = chat transcript between a human and a friendly bot named Buddy.

model = vicuna
model_type = llama
model_size = 7B

# Are you using an uncensored version of the model? yes/no
uncensored = yes

[Chat]

# Delay, in seconds, on how many times the bot will gradually edit the message.
# Warning: anything lower than 3 seconds will eventually trigger the flood control system of telegram APIs.
# Use something lower only if you can achieve a very fast inference.
edit_delay = 3

# LIST OF SOME AVAILABLE MODELS (Remember to download your desired model(s) from model-downloader.py)

# model = Vicuna
# model_type = llama

# model = MPT
# model_type = mpt

# model = GPT4All
# model_type = llama